{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email_Spam_Filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y7VAp-OF0gM"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRYXFBYk1KjG",
        "outputId": "1d6e4af0-5fcb-4575-9add-f05c26d6360b"
      },
      "source": [
        "!wget http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
        "!tar -zxf lingspam_public.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-01 19:27:09--  http://www2.aueb.gr/users/ion/data/lingspam_public.tar.gz\n",
            "Resolving www2.aueb.gr (www2.aueb.gr)... 195.251.255.138\n",
            "Connecting to www2.aueb.gr (www2.aueb.gr)|195.251.255.138|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11564714 (11M) [application/x-gzip]\n",
            "Saving to: ‘lingspam_public.tar.gz’\n",
            "\n",
            "lingspam_public.tar 100%[===================>]  11.03M  1.73MB/s    in 7.0s    \n",
            "\n",
            "2021-11-01 19:27:17 (1.59 MB/s) - ‘lingspam_public.tar.gz’ saved [11564714/11564714]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LivpZgBFow2"
      },
      "source": [
        "# Feature selection using information gain(IG) matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LlHDBou4d7o",
        "outputId": "0d8bfdee-10dd-41aa-e927-721a528929bb"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Copy from readme.txt\n",
        "# Each one of the 10 subdirectories contains both spam and legitimate \n",
        "# messages, one message in each file. Files whose names have the form\n",
        "# spmsg*.txt are spam messages. All other files are legitimate messages.\n",
        "\n",
        "path = \"lingspam_public/lemm_stop\"\n",
        "word_filter = re.compile(r'^[a-z]+-?[a-z]+[0-9]*$')\n",
        "\n",
        "spam_words = []\n",
        "ham_words = []\n",
        "train_X = []\n",
        "train_Y = []\n",
        "spam_num = 0\n",
        "ham_num = 0\n",
        "\n",
        "# Build IG and training dataset\n",
        "for dir in [os.path.join(path, 'part' + str(i)) for i in range(1, 10)]:\n",
        "    mails = [(os.path.join(dir, file_name), 'spmsg' in file_name) for file_name in os.listdir(dir)]\n",
        "    \n",
        "    for file_path, spam in mails:\n",
        "        with open(file_path) as f:\n",
        "            content = f.readlines()[2]\n",
        "            words = content.split()\n",
        "            filtered_words = list(set([w for w in words if (len(w) > 1 and re.match(word_filter, w))]))\n",
        "            # Add words to training set\n",
        "            train_X.append(filtered_words)\n",
        "            # Label spam as 1, ham as 0\n",
        "            if spam:\n",
        "                train_Y.append(1)\n",
        "                spam_words += filtered_words\n",
        "                spam_num += 1\n",
        "            else:\n",
        "                train_Y.append(0)\n",
        "                ham_words += filtered_words\n",
        "                ham_num += 1\n",
        "\n",
        "\n",
        "train_all_counter = Counter(spam_words + ham_words)\n",
        "train_spam_counter = Counter(spam_words)\n",
        "train_ham_counter = Counter(ham_words)\n",
        "\n",
        "print(f'Loading {spam_num + ham_num} emails, {spam_num} of them are spam, \\\n",
        "and {ham_num} of them are ham.')\n",
        "print(f'Within the total of {len(train_all_counter)} words, \\\n",
        "getting {len(train_spam_counter)} words occur in spam, \\\n",
        "and {len(train_ham_counter)} words occur in ham email.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2602 emails, 432 of them are spam, and 2170 of them are ham.\n",
            "Within the total of 48583 words, getting 8657 words occur in spam, and 45091 words occur in ham email.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1RJZKLxOYZx",
        "outputId": "97f3faed-afea-4634-d560-6b6a9e1456ae"
      },
      "source": [
        "print(train_X[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['letter', 'establish', 'convert', 'participate', 'start', 'customer', 'simple', 'interest', 'entire', 'please', 'program', 'mortgage', 'company', 'number', 'ago', 'pull', 'solid', 'main', 'information', 'throw', 'call', 'inexpensive', 'po', 'honestly', 'best', 'later', 'cash', 'grab', 'delete', 'one', 'believe', 'box', 'city', 'id', 'message', 'enable', 'part', 'financial', 'respond', 'detail', 'secure', 'note', 'educational', 'mailer', 'cost', 'lifeline', 'credit', 'today', 'return', 'independence', 'net', 'leverage', 'night', 'address', 'intrusion', 'over', 'offence', 'show', 'simply', 'begin', 'pardon', 'phone', 'grapevine', 'must', 'weekly', 'our', 'week', 'join', 'usa', 'finances', 'mind', 'debt', 'us', 'guarantee', 'computer', 'conference', 'card', 'entitle', 'hello', 'few', 'tuesday', 'cst', 'telephone', 'member', 'name', 'old', 'plan', 'problem', 'center', 'mean', 'solution', 'control', 'zip', 'base', 'complete', 'system', 'receive', 'peace', 'form', 'registration', 'compound', 'pm', 'ignore', 'worth', 'without', 'process', 'life', 'print', 'achieve', 'free', 'outside', 'send', 'especially', 'nobrainer', 'state', 'texa', 'obtain', 'freedom', 'reside']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOO1mu3aI3dY"
      },
      "source": [
        "# Build test data set\n",
        "test_X = []\n",
        "test_Y = []\n",
        "\n",
        "test_path = 'lingspam_public/lemm_stop/part10'\n",
        "test_mail_path = [(os.path.join(test_path, file_name), 'spmsg' in file_name) for file_name in os.listdir(test_path)]\n",
        "for file_path, spam in test_mail_path:\n",
        "    with open(file_path) as f:\n",
        "        content = f.readlines()[2]\n",
        "        words = content.split()\n",
        "        filtered_words = list(set([w for w in words if (len(w) > 1 and re.match(word_filter, w))]))\n",
        "        # Add words to test set\n",
        "        test_X.append(filtered_words)\n",
        "        # Label spam as 1, ham as 0\n",
        "        if spam:\n",
        "            test_Y.append(1)\n",
        "        else:\n",
        "            test_Y.append(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaVWPbC2N2l6"
      },
      "source": [
        "# Helper parameter and function for IG\n",
        "def Log(i):\n",
        "    return np.log(i) if i != 0 else 0\n",
        "\n",
        "\n",
        "total_num = spam_num + ham_num\n",
        "P_SPAM = spam_num / total_num\n",
        "P_HAM = 1 - P_SPAM\n",
        "HC = -P_SPAM * Log(P_SPAM) -P_HAM * Log(P_HAM)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPUataq0cRDN"
      },
      "source": [
        "# Generating IG for all words\n",
        "\n",
        "IG = {}\n",
        "\n",
        "for word in train_all_counter:\n",
        "    all_occur = train_all_counter[word]\n",
        "    spam_occur = train_spam_counter[word]\n",
        "    ham_occur = train_ham_counter[word]\n",
        "\n",
        "    # X=1, C = ham\n",
        "    P1h = (ham_occur / ham_num) * P_HAM\n",
        "    # X=0, C = ham\n",
        "    P0h = (1 - (ham_occur / ham_num)) * P_HAM\n",
        "    # X=1, C = spam\n",
        "    P1s = (spam_occur / spam_num) * P_SPAM\n",
        "    # X=0, C = spam\n",
        "    P0s = (1 - (spam_occur / spam_num)) * P_SPAM\n",
        "    # P(X=1)\n",
        "    P1 = all_occur / total_num\n",
        "    # P(X=0)\n",
        "    P0 = 1 - P1\n",
        "\n",
        "    # Note: H(C|X) = - sum(P(X,C) log(C|X))\n",
        "    # But it is easier to do addition operation here :)\n",
        "    HCX = P1h*Log(P1h/P1) + P0h*Log(P0h/P0) + P1s*Log(P1s/P1) + P0s*Log(P0s/P0)\n",
        "    IG[word] = HC + HCX\n",
        "\n",
        "top_words = [k for k, v in sorted(IG.items(), key=lambda item: -item[1])]\n",
        "top_10 = top_words[:10]\n",
        "top_100 = top_words[:100]\n",
        "top_1000 = top_words[:1000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgdVJD8fiYBs",
        "outputId": "41b3b406-31b0-4c53-a3ac-cf04fadb602a"
      },
      "source": [
        "print(top_10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG_nMu4yGC9H"
      },
      "source": [
        "# Classifiers Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAeg3eUTFQB0"
      },
      "source": [
        "## Generate Feature Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ste0_cUBFcfF"
      },
      "source": [
        "def get_feature(N, dataset, term_frequency=False):\n",
        "    \"\"\"Generate feature matrix based on top N words.\"\"\"\n",
        "    # print(term_frequency)\n",
        "    top_n = {v:i for i,v in enumerate(top_words[:N])}\n",
        "    feature_matrix = np.zeros((len(dataset), N))\n",
        "    for j, content in enumerate(dataset):\n",
        "        for word in content:\n",
        "            if word in top_n:\n",
        "                if term_frequency:\n",
        "                    feature_matrix[j, top_n[word]] += 1\n",
        "                else:\n",
        "                    feature_matrix[j, top_n[word]] = 1\n",
        "    \n",
        "    return feature_matrix"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kchPZ9QojUJ7"
      },
      "source": [
        "## Bernoulli NB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viC-osOlGr6l"
      },
      "source": [
        "class BNB:\n",
        "    \"\"\"Naive Bayes classifier for multivariate Bernoulli models.\"\"\"\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha  # Actually, no need in this homework :)\n",
        "        self.spam_num = 0\n",
        "        self.ham_num = 0\n",
        "        self.P_X_spam = []\n",
        "        self.P_X_ham = []\n",
        "\n",
        "\n",
        "    def fit(self, train_x, train_y):\n",
        "        \"\"\"Fit Naive Bayes classifier according to train_x, train_y.\"\"\"\n",
        "        self.spam_num = sum(train_y)\n",
        "        self.ham_num = len(train_y) - sum(train_y)\n",
        "        rows, feature_num = train_x.shape\n",
        "\n",
        "        self.P_X_spam = np.zeros(feature_num)\n",
        "        self.P_X_ham = np.zeros(feature_num)\n",
        "        for i in range(feature_num):\n",
        "            x_spam = 0\n",
        "            x_ham = 0\n",
        "            for j in range(rows):\n",
        "                if train_x[j,i]:\n",
        "                    if train_y[j]:\n",
        "                        x_spam += 1\n",
        "                    else:\n",
        "                        x_ham += 1\n",
        "            self.P_X_spam[i] = (1 + x_spam) / (self.spam_num + 2)\n",
        "            self.P_X_ham[i] = (1 + x_ham) / (self.ham_num + 2)\n",
        "\n",
        "\n",
        "    def _row_predict(self, one_sample):\n",
        "        \"\"\"Predict one record of the data set.\"\"\"\n",
        "        prob = 1\n",
        "        for i, feature in enumerate(one_sample):\n",
        "            p0 = self.P_X_ham[i]\n",
        "            p1 = self.P_X_spam[i]\n",
        "            prob *= (p1 / p0) if feature == 1 else (1 - p1) / (1 - p0)\n",
        "        return prob * self.spam_num / self.ham_num\n",
        "\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        \"\"\"Perform classification on an array of test vectors test_x.\"\"\"\n",
        "        pred = np.zeros((test_x.shape[0]))\n",
        "        for i in range(test_x.shape[0]):\n",
        "            pred[i] = int(self._row_predict(test_x[i]) > 1)\n",
        "        return pred\n",
        "    \n",
        "\n",
        "    def score(self, test_x, test_y):\n",
        "        \"\"\"Return the mean accuracy on the given test data and labels.\"\"\"\n",
        "        y_pred = self.predict(test_x)\n",
        "        count = 0\n",
        "        for i in range(len(test_y)):\n",
        "            count += 1 if y_pred[i] == test_y[i] else 0\n",
        "        return count / len(test_y)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgWcyoKJdn-0"
      },
      "source": [
        "## Multinominal NB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh5zP_1JeBQ_"
      },
      "source": [
        "class MNB:\n",
        "    \"\"\"Naive Bayes classifier for multinomial models.\"\"\"\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.spam_num = 0\n",
        "        self.ham_num = 0\n",
        "        self.P_X_spam = []\n",
        "        self.P_X_ham = []\n",
        "\n",
        "\n",
        "    def fit(self, train_x, train_y):\n",
        "        \"\"\"Fit Naive Bayes classifier according to train_x, train_y.\"\"\"\n",
        "        self.spam_num = sum(train_y)\n",
        "        self.ham_num = len(train_y) - sum(train_y)\n",
        "        rows, feature_num = train_x.shape\n",
        "\n",
        "        self.P_X_spam = np.zeros(feature_num)\n",
        "        self.P_X_ham = np.zeros(feature_num)\n",
        "        for i in range(feature_num):\n",
        "            x_spam = 0\n",
        "            x_ham = 0\n",
        "            for j in range(rows):\n",
        "                if train_x[j,i]:\n",
        "                    if train_y[j]:\n",
        "                        x_spam += 1\n",
        "                    else:\n",
        "                        x_ham += 1\n",
        "            self.P_X_spam[i] = (1 + x_spam) / (self.spam_num + 2)\n",
        "            self.P_X_ham[i] = (1 + x_ham) / (self.ham_num + 2)\n",
        "    \n",
        "\n",
        "    def _row_predict(self, one_sample):\n",
        "        \"\"\"Predict one record of the data set.\"\"\"\n",
        "        prob = 1\n",
        "        for i, feature in enumerate(one_sample):\n",
        "            p0 = self.P_X_ham[i]\n",
        "            p1 = self.P_X_spam[i]\n",
        "            prob += (Log(p1) - Log(p0)) if feature == 1 else 0\n",
        "        return prob + Log(self.spam_num) - Log(self.ham_num)\n",
        "\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        \"\"\"Perform classification on an array of test vectors test_x.\"\"\"\n",
        "        pred = np.zeros((test_x.shape[0]))\n",
        "        for i in range(test_x.shape[0]):\n",
        "            pred[i] = int(self._row_predict(test_x[i]) > 0)\n",
        "        return pred\n",
        "    \n",
        "\n",
        "    def score(self, test_x, test_y):\n",
        "        \"\"\"Return the mean accuracy on the given test data and labels.\"\"\"\n",
        "        y_pred = self.predict(test_x)\n",
        "        count = 0\n",
        "        for i in range(len(test_y)):\n",
        "            count += 1 if y_pred[i] == test_y[i] else 0\n",
        "        return count / len(test_y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JgPvjPCGPA0"
      },
      "source": [
        "# Classifiers Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDUIW0eZG2jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84417a87-23d7-4664-d095-eb7097132ec3"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "top_N = [10, 100, 1000]\n",
        "result_accuracy = []\n",
        "\n",
        "for N in top_N:\n",
        "    Xprint = get_feature(N, train_X)\n",
        "    # X label with term frequency\n",
        "    X_tf = get_feature(N, train_X, term_frequency=True)\n",
        "    Y = np.array(train_Y)\n",
        "\n",
        "    X_test = get_feature(N, test_X)\n",
        "    # X label with term frequency\n",
        "    X_test_tf = get_feature(N, test_X, term_frequency=True)\n",
        "    Y_test = np.array(test_Y)\n",
        "\n",
        "    model1 = BNB()\n",
        "    model2 = MNB()\n",
        "    model3 = MNB()\n",
        "\n",
        "    # train models\n",
        "    model1.fit(X, Y)\n",
        "    model2.fit(X, Y)\n",
        "    model3.fit(X_tf, Y)\n",
        "\n",
        "    # predict\n",
        "    y_1 = model1.predict(X_test)\n",
        "    y_2 = model2.predict(X_test)\n",
        "    y_3 = model3.predict(X_test_tf)\n",
        "\n",
        "    print(f'--------------- Using top {N} features --------------')\n",
        "    print( '--------------- Bernoulli Naive Bayes ---------------')\n",
        "    print(classification_report(Y_test,y_1, target_names = [\"ham\", \"spam\"]))\n",
        "    print('--- Multinominal Naive Bayes with binary features ---')\n",
        "    print(classification_report(Y_test,y_2, target_names = [\"ham\", \"spam\"]))\n",
        "    print('---- Multinominal Naive Bayes with term frequency ---')\n",
        "    print(classification_report(Y_test,y_3, target_names = [\"ham\", \"spam\"]))\n",
        "\n",
        "    N_accuray = [model1.score(X_test,Y_test), \n",
        "                 model2.score(X_test,Y_test), \n",
        "                 model3.score(X_test_tf,Y_test)]\n",
        "    result_accuracy.append(N_accuray)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- Using top 10 features --------------\n",
            "--------------- Bernoulli Naive Bayes ---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.98      0.97       242\n",
            "        spam       0.89      0.82      0.85        49\n",
            "\n",
            "    accuracy                           0.95       291\n",
            "   macro avg       0.93      0.90      0.91       291\n",
            "weighted avg       0.95      0.95      0.95       291\n",
            "\n",
            "--- Multinominal Naive Bayes with binary features ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.95      0.97       242\n",
            "        spam       0.80      0.92      0.86        49\n",
            "\n",
            "    accuracy                           0.95       291\n",
            "   macro avg       0.89      0.94      0.91       291\n",
            "weighted avg       0.95      0.95      0.95       291\n",
            "\n",
            "---- Multinominal Naive Bayes with term frequency ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.95      0.97       242\n",
            "        spam       0.80      0.92      0.86        49\n",
            "\n",
            "    accuracy                           0.95       291\n",
            "   macro avg       0.89      0.94      0.91       291\n",
            "weighted avg       0.95      0.95      0.95       291\n",
            "\n",
            "--------------- Using top 100 features --------------\n",
            "--------------- Bernoulli Naive Bayes ---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.94      1.00      0.97       242\n",
            "        spam       1.00      0.67      0.80        49\n",
            "\n",
            "    accuracy                           0.95       291\n",
            "   macro avg       0.97      0.84      0.89       291\n",
            "weighted avg       0.95      0.95      0.94       291\n",
            "\n",
            "--- Multinominal Naive Bayes with binary features ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.98      0.99       242\n",
            "        spam       0.89      1.00      0.94        49\n",
            "\n",
            "    accuracy                           0.98       291\n",
            "   macro avg       0.95      0.99      0.96       291\n",
            "weighted avg       0.98      0.98      0.98       291\n",
            "\n",
            "---- Multinominal Naive Bayes with term frequency ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.98      0.99       242\n",
            "        spam       0.89      1.00      0.94        49\n",
            "\n",
            "    accuracy                           0.98       291\n",
            "   macro avg       0.95      0.99      0.96       291\n",
            "weighted avg       0.98      0.98      0.98       291\n",
            "\n",
            "--------------- Using top 1000 features --------------\n",
            "--------------- Bernoulli Naive Bayes ---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96       242\n",
            "        spam       1.00      0.61      0.76        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.96      0.81      0.86       291\n",
            "weighted avg       0.94      0.93      0.93       291\n",
            "\n",
            "--- Multinominal Naive Bayes with binary features ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      1.00      1.00       242\n",
            "        spam       1.00      1.00      1.00        49\n",
            "\n",
            "    accuracy                           1.00       291\n",
            "   macro avg       1.00      1.00      1.00       291\n",
            "weighted avg       1.00      1.00      1.00       291\n",
            "\n",
            "---- Multinominal Naive Bayes with term frequency ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      1.00      1.00       242\n",
            "        spam       1.00      1.00      1.00        49\n",
            "\n",
            "    accuracy                           1.00       291\n",
            "   macro avg       1.00      1.00      1.00       291\n",
            "weighted avg       1.00      1.00      1.00       291\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIQPvjCrInaw"
      },
      "source": [
        "## Spam precision and spam recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Tg7bZ8ItUC"
      },
      "source": [
        "\n",
        "| Params                                                       | Spam Precision | Spam Recall |\n",
        "| ------------------------------------------------------------ | -------------- | ----------- |\n",
        "| Top 10 Words, Bernoulli Naive Bayes                          |0.89           | 0.82         |\n",
        "| Top 10 Words, Multinominal Naive Bayes with binary features  |0.80            | 0.92         |\n",
        "| Top 10 Words, Multinominal Naive Bayes with term frequency   |0.80           | 0.92        |\n",
        "| Top 100 Words, Bernoulli Naive Bayes                         |1.00           | 0.67        |\n",
        "| Top 100 Words, Multinominal Naive Bayes with binary features |0.89           | 1.00        |\n",
        "| Top 100 Words, Multinominal Naive Bayes with term frequency  |0.89           | 1.00        |\n",
        "| Top 1000 Words, Bernoulli Naive Bayes                        |1.00           | 0.61        |\n",
        "| Top 1000 Words, Multinominal Naive Bayes with binary features|1.00           | 1.00        |\n",
        "| Top 1000 Words, Multinominal Naive Bayes with term frequency |1.00           | 1.00        |\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWHJad5ZAwn6"
      },
      "source": [
        "## Compare with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTrge4-2A1wp",
        "outputId": "e4ab3f97-f658-4340-b37d-c8ba69adb382"
      },
      "source": [
        "result_accuracy_sk = []\n",
        "\n",
        "for N in top_N:\n",
        "    model1_sk = BernoulliNB()\n",
        "    model2_sk = MultinomialNB()\n",
        "    model3_sk = MultinomialNB()\n",
        "\n",
        "    X = get_feature(N, train_X)\n",
        "    X_tf = get_feature(N, train_X, term_frequency=True)\n",
        "    Y = np.array(train_Y)\n",
        "\n",
        "    X_test = get_feature(N, test_X)\n",
        "    X_test_tf = get_feature(N, test_X, term_frequency=True)\n",
        "    Y_test = np.array(test_Y)\n",
        "\n",
        "    # train models\n",
        "    model1_sk.fit(X, Y)\n",
        "    model2_sk.fit(X, Y)\n",
        "    model3_sk.fit(X_tf, Y)\n",
        "\n",
        "    # predict\n",
        "    N_accuray = [model1_sk.score(X_test,Y_test), \n",
        "                 model2_sk.score(X_test,Y_test), \n",
        "                 model3_sk.score(X_test_tf,Y_test)]\n",
        "    result_accuracy_sk.append(N_accuray)\n",
        "\n",
        "\n",
        "print(result_accuracy)\n",
        "print(result_accuracy_sk)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9518900343642611, 0.9484536082474226, 0.9484536082474226], [0.9450171821305842, 0.979381443298969, 0.979381443298969], [0.9347079037800687, 1.0, 1.0]]\n",
            "[[0.9518900343642611, 0.9518900343642611, 0.9518900343642611], [0.9450171821305842, 0.9828178694158075, 0.9828178694158075], [0.9347079037800687, 0.9896907216494846, 0.9896907216494846]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_7Lcd0vGnv9"
      },
      "source": [
        "# SVM based spam filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FABaNWhRG3DF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18abbdd-cb8f-4b1c-8b81-3df2dc33d139"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.base import clone\n",
        "\n",
        "\n",
        "feature_sizes = [10, 100, 200]\n",
        "modes = [\"bf\", \"tf\"]\n",
        "gamma = [1, 0.1, 0.01, 0.001]\n",
        "C = [0.1, 1, 10, 100]\n",
        "degree = [2,3,10]\n",
        "tuned_parameters = [{'kernel': ['rbf','sigmoid'], 'gamma': gamma,'C': C},\n",
        "                    {'kernel': ['linear'], 'C': C},\n",
        "                    {'kernel': ['poly'], 'gamma': gamma, \"degree\" : degree, 'C':C}\n",
        "                    ]\n",
        "now_best = {}\n",
        "now_score = 0\n",
        "best_clf = SVC()\n",
        "for N in feature_sizes:\n",
        "    for mode in modes:\n",
        "        X = get_feature(N, train_X, term_frequency=(mode=='tf'))\n",
        "        X_test = get_feature(N, test_X, term_frequency=(mode=='tf'))\n",
        "        Y = np.array(train_Y)\n",
        "        if mode == 'tf':\n",
        "            ss = MinMaxScaler()\n",
        "            X = ss.fit_transform(X)\n",
        "            X_test = ss.transform(X_test)\n",
        "        clf = GridSearchCV(SVC(), tuned_parameters, cv = 5, scoring='recall_macro', verbose = 0, n_jobs = -1)\n",
        "        clf.fit(X, Y)\n",
        "        \n",
        "        if clf.best_score_ > now_score:\n",
        "            now_score = clf.best_score_\n",
        "            now_best = {\"size\":N, \"mode\":mode, \"score\":clf.best_score_, \"params\":clf.best_params_}\n",
        "            best_clf = clone(clf.best_estimator_)\n",
        "            print (now_best)\n",
        "\n",
        "N = now_best[\"size\"]\n",
        "mode = now_best[\"mode\"]\n",
        "X = get_feature(N, train_X, term_frequency=(mode=='tf'))\n",
        "X_test = get_feature(N, test_X, term_frequency=(mode=='tf'))\n",
        "Y = np.array(train_Y)\n",
        "Y_test = np.array(test_Y)\n",
        "\n",
        "if mode == \"tf\":\n",
        "    ss = MinMaxScaler()\n",
        "    X = ss.fit_transform(X)\n",
        "    X_test = ss.transform(X_test)\n",
        "\n",
        "best_clf.fit(X, Y)\n",
        "pred_y = best_clf.predict(X_test)\n",
        "print (now_best)\n",
        "print (classification_report(Y_test, pred_y, target_names = [\"ham\", \"spam\"]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'size': 10, 'mode': 'bf', 'score': 0.9333773098447026, 'params': {'C': 1, 'gamma': 1, 'kernel': 'rbf'}}\n",
            "{'size': 100, 'mode': 'bf', 'score': 0.9611211300362037, 'params': {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}}\n",
            "{'size': 200, 'mode': 'bf', 'score': 0.9699466122688307, 'params': {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}}\n",
            "{'size': 200, 'mode': 'bf', 'score': 0.9699466122688307, 'params': {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99       242\n",
            "        spam       0.98      0.88      0.92        49\n",
            "\n",
            "    accuracy                           0.98       291\n",
            "   macro avg       0.98      0.94      0.96       291\n",
            "weighted avg       0.98      0.98      0.98       291\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfJAxCMXfF52"
      },
      "source": [
        "## Methodology\n",
        "I use ```GridSearchCV``` to help me find the best parameters for SVM. Also, we've see that higher Information Gain feature matrix can have a better result in prediction. So I compare the score between \"BF\" and \"TF\" and the score among \"N={10, 100, 200}\". The result shows that using **top 200** words, **binary features**, and ```{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}``` as the SVM parameter can get the best result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Sk7qU4G3YC"
      },
      "source": [
        "# Adversarial Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYtauhW7F2E"
      },
      "source": [
        "## Attacker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAeuIBpaHFU_"
      },
      "source": [
        "class Attacker:\n",
        "    def __init__(self):\n",
        "        self.Lo = []\n",
        "        self.Lo0 = []\n",
        "        self.Lo1 = []\n",
        "\n",
        "\n",
        "    def cal_Lo(self, train_x, train_y):\n",
        "        rows, feature_num = train_x.shape\n",
        "        self.Lo = np.zeros(feature_num)\n",
        "        self.Lo0 = np.zeros(feature_num)\n",
        "        self.Lo1 = np.zeros(feature_num)\n",
        "\n",
        "        for i in range(feature_num):\n",
        "            x_spam = 0\n",
        "            x_ham = 0\n",
        "            for j in range(rows):\n",
        "                if train_x[j,i]:\n",
        "                    if train_y[j]:\n",
        "                        x_spam += 1\n",
        "                    else:\n",
        "                        x_ham += 1\n",
        "            P_X1_ham = x_ham / ham_num\n",
        "            P_X1_spam = x_spam / spam_num\n",
        "            P_X0_ham = 1 - P_X1_ham\n",
        "            P_X0_spam = 1 - P_X1_spam\n",
        "            self.Lo1[i] = Log(P_X1_spam/P_X1_ham)\n",
        "            self.Lo0[i] = Log(P_X0_spam/P_X0_ham)\n",
        "            self.Lo[i] = self.Lo1[i] - self.Lo0[i]\n",
        "\n",
        "\n",
        "    def _row_attack(self, one_sample):\n",
        "        sort_Lo = sorted(range(len(self.Lo)), key=lambda i: self.Lo[i])\n",
        "\n",
        "        cost = 0\n",
        "        sigmaLoX = 0\n",
        "        for i,v in enumerate(one_sample):\n",
        "            sigmaLoX += self.Lo1[i] if v==1 else self.Lo0[i]\n",
        "        if sigmaLoX < 0:\n",
        "            return 0, one_sample\n",
        "\n",
        "        for i in sort_Lo:\n",
        "            if(self.Lo[i] >= 0):\n",
        "                return cost, one_sample\n",
        "            if one_sample[i]:\n",
        "                continue\n",
        "            one_sample[i] = 1\n",
        "            sigmaLoX += self.Lo[i]\n",
        "            cost += 1\n",
        "            if (sigmaLoX < 0):\n",
        "                return cost, one_sample\n",
        "\n",
        "\n",
        "    def attack(self, test_x, test_y):\n",
        "        costs = []\n",
        "        new_test_x = []\n",
        "        rows, feature_num = test_x.shape\n",
        "        for i in range(rows):\n",
        "            if test_y[i]:\n",
        "                cost, changed = self._row_attack(test_x[i])\n",
        "                new_test_x.append(changed)\n",
        "                costs.append(cost)\n",
        "            else:\n",
        "                new_test_x.append(test_x[i])\n",
        "        \n",
        "        return np.mean(costs), np.array(new_test_x)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBKTVJ1m7QmZ"
      },
      "source": [
        "## Defender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwzhZ8uY7Smc"
      },
      "source": [
        "class Defender:\n",
        "    def __init__(self):\n",
        "        self.P_X1_ham = []\n",
        "        self.P_X1_spam = []\n",
        "        self.P_X0_ham = []\n",
        "        self.P_X0_spam = []\n",
        "        self.Lo = []\n",
        "        self.Lo0 = []\n",
        "        self.Lo1 = []\n",
        "        self.result = []\n",
        "\n",
        "    def fit(self, train_x, train_y):\n",
        "        rows, feature_num = train_x.shape\n",
        "        self.P_X1_ham = np.zeros(feature_num)\n",
        "        self.P_X1_spam = np.zeros(feature_num)\n",
        "        self.P_X0_ham = np.zeros(feature_num)\n",
        "        self.P_X0_spam = np.zeros(feature_num)\n",
        "        self.Lo = np.zeros(feature_num)\n",
        "        self.Lo0 = np.zeros(feature_num)\n",
        "        self.Lo1 = np.zeros(feature_num)\n",
        "\n",
        "        for i in range(feature_num):\n",
        "            x_spam = 0\n",
        "            x_ham = 0\n",
        "            for j in range(rows):\n",
        "                if train_x[j,i]:\n",
        "                    if train_y[j]:\n",
        "                        x_spam += 1\n",
        "                    else:\n",
        "                        x_ham += 1\n",
        "            self.P_X1_ham[i] = x_ham / ham_num\n",
        "            self.P_X1_spam[i] = x_spam / spam_num\n",
        "            self.P_X0_ham[i] = 1 - self.P_X1_ham[i]\n",
        "            self.P_X0_spam[i] = 1 - self.P_X1_spam[i]\n",
        "            self.Lo1[i] = Log(self.P_X1_spam[i] / self.P_X1_ham[i])\n",
        "            self.Lo0[i] = Log(self.P_X0_spam[i] / self.P_X0_ham[i])\n",
        "            self.Lo[i] = self.Lo1[i] - self.Lo0[i]\n",
        "\n",
        "\n",
        "    def _row_attack(self, one_sample):\n",
        "        sort_Lo = sorted(range(len(self.Lo)), key=lambda i: self.Lo[i])\n",
        "\n",
        "        cost = 0\n",
        "        sigmaLoX = 0\n",
        "        for i,v in enumerate(one_sample):\n",
        "            sigmaLoX += self.Lo1[i] if v==1 else self.Lo0[i]\n",
        "        if sigmaLoX < 0:\n",
        "            return 0, one_sample\n",
        "\n",
        "        for i in sort_Lo:\n",
        "            if(self.Lo[i] >= 0):\n",
        "                return cost, one_sample\n",
        "            if one_sample[i]:\n",
        "                continue\n",
        "            one_sample[i] = 1\n",
        "            sigmaLoX += self.Lo[i]\n",
        "            cost += 1\n",
        "            if (sigmaLoX < 0):\n",
        "                return cost, one_sample\n",
        "\n",
        "\n",
        "    def defence(self, model, attacked_x):\n",
        "        for sample in attacked_x:\n",
        "            if model._row_predict(sample):\n",
        "                self.result += [1]\n",
        "                continue\n",
        "            new_matrix = [[]]\n",
        "            for i in sample:\n",
        "                if i:\n",
        "                    new_row = [(x + [0]) for x in new_matrix] + [(x + [1]) for x in new_matrix]\n",
        "                else:\n",
        "                    new_matrix_f = [(x + [0]) for x in new_matrix]\n",
        "                new_matrix = new_matrix_f\n",
        "            new_matrix = [np.asarray(x) for x in new_matrix]\n",
        "            realFroms = []\n",
        "            for origin in new_matrix:\n",
        "                _, attacked = self._row_attack(origin)\n",
        "                if np.array_equal(attacked, sample):\n",
        "                    if model._row_predict(origin):\n",
        "                        realFroms += [origin]\n",
        "            if len(realFroms):\n",
        "                P_spam = 0\n",
        "                P_ham = 0\n",
        "                for origin in realFroms:\n",
        "                    for i in origin:\n",
        "                        P_spam *= self.P_X1_spam[i] if i else self.P_X0_spam[i]\n",
        "                        P_ham *= self.P_X1_ham[i] if i else self.P_X0_ham[i]\n",
        "                    P_spam += 1\n",
        "                    P_ham += 1\n",
        "                self.result += [0 if P_spam < P_ham else 1]\n",
        "            else:\n",
        "                self.result += [0]\n",
        "        \n",
        "        return np.array(self.result)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZDgnkxa7Tx9"
      },
      "source": [
        "## Adversarial attack analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTOYr2jF7jKN",
        "outputId": "ed187fec-c350-453a-a098-c86c738e63e7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "N = 10\n",
        "X = get_feature(N, train_X)\n",
        "Y = np.array(train_Y)\n",
        "X_test = get_feature(N, test_X)\n",
        "Y_test = np.array(test_Y)\n",
        "\n",
        "# Use original model to predict Y_test\n",
        "botnet = BNB()\n",
        "botnet.fit(X, Y)\n",
        "Y_pred_origin = botnet.predict(X_test)\n",
        "print(\"Original classification report before attack\")\n",
        "print(classification_report(Y_test, Y_pred_origin, target_names = [\"ham\", \"spam\"]))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(Y_test, Y_pred_origin))\n",
        "\n",
        "# Assume that Attacker knows \n",
        "# - original model's result: Y_pred_origin\n",
        "# - original test words list: test_X\n",
        "# - oringinal test label: test_Y\n",
        "# Using 'Add-Words' attack\n",
        "hacker = Attacker()\n",
        "hacker.cal_Lo(X, Y)\n",
        "cost, X_test_attacked = hacker.attack(X_test, Y_test)\n",
        "Y_pred_attacked = botnet.predict(X_test_attacked)\n",
        "print(\"Original classification report after attack\")\n",
        "print(classification_report(Y_test, Y_pred_attacked, target_names = [\"ham\", \"spam\"]))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(Y_test, Y_pred_attacked))\n",
        "print(f\"Average cost = {cost}\")\n",
        "\n",
        "# Denfender\n",
        "antispam = Defender()\n",
        "antispam.fit(X, Y)\n",
        "Y_pred_defence = antispam.defence(botnet, X_test_attacked)\n",
        "print(\"Original classification report after defence\")\n",
        "print(classification_report(Y_test, Y_pred_defence, target_names = [\"ham\", \"spam\"]))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(Y_test, Y_pred_defence))\n",
        "print(f\"Average cost = {cost}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original classification report before attack\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.98      0.97       242\n",
            "        spam       0.89      0.82      0.85        49\n",
            "\n",
            "    accuracy                           0.95       291\n",
            "   macro avg       0.93      0.90      0.91       291\n",
            "weighted avg       0.95      0.95      0.95       291\n",
            "\n",
            "Confusion Matrix\n",
            "[[237   5]\n",
            " [  9  40]]\n",
            "Original classification report after attack\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.83      0.98      0.90       242\n",
            "        spam       0.29      0.04      0.07        49\n",
            "\n",
            "    accuracy                           0.82       291\n",
            "   macro avg       0.56      0.51      0.49       291\n",
            "weighted avg       0.74      0.82      0.76       291\n",
            "\n",
            "Confusion Matrix\n",
            "[[237   5]\n",
            " [ 47   2]]\n",
            "Average cost = 1.7959183673469388\n",
            "Original classification report after defence\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.00      0.00      0.00       242\n",
            "        spam       0.17      1.00      0.29        49\n",
            "\n",
            "    accuracy                           0.17       291\n",
            "   macro avg       0.08      0.50      0.14       291\n",
            "weighted avg       0.03      0.17      0.05       291\n",
            "\n",
            "Confusion Matrix\n",
            "[[  0 242]\n",
            " [  0  49]]\n",
            "Average cost = 1.7959183673469388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}